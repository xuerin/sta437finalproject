---
title: "Multivariate Routes Through Traffic Anomalies"
author: "Erin Xu"
date: "December 1st, 2025"
output:
  pdf_document:
    latex_engine: xelatex
  header-includes:
      - \usepackage{xurl}
      - \usepackage[hidelinks]{hyperref}
      - \usepackage{float}
fontsize: 12pt
bibliography: references.bib
csl: apa.csl
nocite: '@*'
link-citations: true
---
## Introduction
Due to the unavoidable nature of traffic congestion in urban locations, studying its patterns and underlying dynamics enables daily commuters and transportation authorities to transition from reactive management to proactive intervention, leading to overall reduced congestion, lower emissions and improved commuter safety around high-density areas. However, accurately detecting and predicting traffic anomalies that cause significant delays remains a challenge due to the inherent complexity of traffic dynamics, which are continuous, stochastic, spatiotemporally autocorrelated and cross-correlated [@columbia_spatiotemporal]. 

As existing prediction has evolved from interval-based pointwise in univariate time-series data to a functional approach at the network-level utilizing neural networks [@ma2024network], this project offers a comparative assessment of common multivariate statistical techniques that are highly interpretable as benchmarks for further study. The goal of this paper is to identify and classify location-specific anomalies from the intraday patterns of traffic volume flow collected across 26 monitoring sites around the University of Toronto by comparing principal component analysis (PCA), factor analysis (FA), and independent component analysis (ICA) methods, which are selected for their ability to achieve dimension reduction, interpret latent regimes, and isolate mixed data components. 

## Data Description
The dataset, synthetically modeled from @ma2024network, has a natural tensor structure consisting of 26 locations ($l$), 384 ($n$) days each, and 288 ($p$) five-minute time points per day. Then each slice $X \in \mathbb{R^{n \times p}}$, called the daily traffic matrix, corresponds to one location and forms a $384 \times 288$ matrix, with each entry as volume in vehicles. 

No data cleaning was required, as all locations share uniform dimensions and contain no missing observations. Exploratory visualizations were produced for two randomly selected locations to conserve space. Spaghetti plots by location and by day, accompanied by summary statistics, highlight clear daily peak structures. The first location exhibits lower median flow than the second, suggesting a less trafficked or more residential area. In contrast, the two randomly sampled days display similar median volumes, consistent with typical weekday patterns. These preliminary observations motivate the subsequent use of statistical methods to quantify temporal and spatial structure in the full dataset.

The coefficient of variation (CV) and autocorrelation function (ACF) analyses indicate that the traffic system exhibits a strong diurnal rhythm and persistent temporal dependence, supporting the use of dimension-reduction methods. CV quantifies day-to-day variability at each 5-minute interval. Averaged across locations, the CV curve shows highest variability overnight, a sharp decline during the morning, and a pronounced minimum around midday, followed by increasing variability toward the evening peak. The narrow CV shadow around noon suggests highly consistent midday traffic, whereas the wider shadow during peak hours reflects differing commuter patterns across locations.

Temporal autocorrelation was assessed at a representative site (Location 5), selected because its mean CV is closest to the median across all locations. The ACF reveals strong short-term persistence: autocorrelation decays gradually over several hours and remains positive even at four-hour lags, implying that intraday traffic evolves smoothly. The absence of negative correlations indicates a stable daily cycle.

The spatial correlation heatmap has shows that the center locations generally are correlated with each other, which suggests functional subregions where locations follow similar demand cycles. Most correlations fall in the moderate positive range, indicating coordinated but heterogeneous behavior across the network. Therefore location-specific anomaly detection is meaningful with location specific nuances, and network-wide patterns could also be coherent enough as the system has shared temporal dynamics.

```{r setup, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(openxlsx)
library(patchwork)
library(reshape2)
library(knitr)
library(kableExtra)
library(corrplot)
library(fastICA)
library(tidyr)
library(cluster)
file <- "traffic.xlsx"
sheet_names <- getSheetNames(file)
num_sheets <- length(sheet_names)
set.seed(67)
df <- lapply(sheet_names, function(sheet) {
  as.matrix(read.xlsx(file, sheet = sheet, colNames = TRUE))
})

names(df) <- sheet_names
set.seed(67)

# Store in list because dealing with 26 locations
data_list <- list()  # Original: time points times days
data_transposed <- list()  # Transposed: days times time points
sample_sheets <- sample(sheet_names, 2)
random_days <- sample(1:384, 2)

data_list <- list()
data_transposed <- list()

for (sheet in sheet_names) {
  X <- df[[sheet]]
  X_t <- t(X)
  data_list[[sheet]] <- X
  data_transposed[[sheet]] <- as.data.frame(X_t)
}
```

```{r spaghetti_loc, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Spaghetti Plot by Location", fig.pos='h'}

spaghettis <- list()

for (sheet in sample_sheets) {

  # Data: 384 days × 288 timepoints
  df_t <- data_transposed[[sheet]]
  df_t$Day <- 1:nrow(df_t)

  # Long format
  df_long <- df_t %>%
    pivot_longer(cols = -Day,
                 names_to = "Time",
                 values_to = "Value") %>%
    mutate(Time = as.numeric(Time))

  # ---- Summary Stats ----
  stats_text <- capture.output(summary(df_long$Value))
  stats_text <- paste(stats_text, collapse = "\n")

 stats_plot <- ggplot() +
  annotate("text", x = 0.5, y = 0.5,
           label = stats_text,
           size = 3.5, hjust = 0.5, vjust = 0.5,
           family = "mono") +
  theme_void() +
  labs(title = paste("Summary for", sheet)) + theme(plot.title = element_text(size = 7))

  # ---- Spaghetti Plot ----
  p <- ggplot(df_long, aes(x = Time, y = Value, group = Day)) +
    geom_line(alpha = 0.15) +
    labs(
      title = paste("Daily Traffic Flow Patterns:", sheet),
      x = "Time (5-min intervals)",
      y = "Traffic Volume"
    ) +
    theme_minimal()+
    theme(plot.title = element_text(size = 7))
  # ---- Combine side-by-side ----
  spaghettis[[sheet]] <- p | stats_plot
}

wrap_plots(spaghettis, ncol = 1)
```

```{r spaghetti_day, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Spaghetti Plot by Day", fig.pos='h'}

spag_time <- list()

for (d in random_days) {

  df_day <- data.frame()
  for (sheet in names(data_list)) {
    X <- data_list[[sheet]]

    temp <- data.frame(
      Time = 1:nrow(X),
      Value = X[, d],
      Location = sheet
    )
    df_day <- rbind(df_day, temp)
  }

  stats_text <- capture.output(summary(df_day$Value))
  stats_text <- paste(stats_text, collapse = "\n")

  stats_plot <- ggplot() +
    annotate("text", x = 0.5, y = 0.5,
             label = stats_text,
             size = 3.5, hjust = 0.5, vjust = 0.5,
             family = "mono") +
    theme_void() +
    labs(title = paste("Summary for Day", d)) + theme(plot.title = element_text(size = 7))

  p <- ggplot(df_day, aes(x = Time, y = Value, group = Location, color = Location)) +
    geom_line(alpha = 0.15) +
    labs(
      title = paste("Traffic Across All Locations on Day", d),
      x = "Time (5-min intervals)",
      y = "Traffic Volume"
    ) +
    theme_minimal() +
    theme(legend.position = "none") + theme(plot.title = element_text(size = 7))

  spag_time[[paste0("Day_", d)]] <- stats_plot | p
}

wrap_plots(spag_time, ncol = 1)
```

```{r cv-acf, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="CV and ACF", fig.pos='h'}

# Create time labels
time_labels <- format(
  seq(from = as.POSIXct("00:00", format="%H:%M"),
      by = "5 min", length.out = 288),
  "%H:%M"
)

# Store CV for each location (one column per location)
cv_by_time <- data.frame(Time = time_labels)

for (sheet in names(data_transposed)) {
  df <- data_transposed[[sheet]]   # 384 × 288
  
  # CV at each timepoint across all days
  cv <- apply(df, 2, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE))
  
  cv_by_time[[sheet]] <- cv
}

# Summary across all locations
avg_cv <- data.frame(
  Time = 1:288,
  AvgCV = rowMeans(cv_by_time[, -1], na.rm = TRUE),
  MinCV = apply(cv_by_time[, -1], 1, min, na.rm = TRUE),
  MaxCV = apply(cv_by_time[, -1], 1, max, na.rm = TRUE)
)

# Plot CV curves
cv <- ggplot(avg_cv, aes(x = Time, y = AvgCV)) +
  geom_ribbon(aes(ymin = MinCV, ymax = MaxCV), fill = "steelblue", alpha = 0.15) +
  geom_line(color = "steelblue", size = 1) +
  labs(
    title = "Traffic Variability Throughout the Day",
    subtitle = "Coefficient of Variation (CV = SD / Mean) across all locations",
    x = "Time of Day",
    y = "Coefficient of Variation"
  ) +
  scale_x_continuous(
    breaks = seq(1, 288, length.out = 7),
    labels = c("00:00", "04:00", "08:00", "12:00", "16:00", "20:00", "24:00")
  ) +
  theme_minimal() + theme(plot.title = element_text(size = 7)) + theme(plot.subtitle = element_text(size = 7))

cv_location_summary <- data.frame(
  Location = names(cv_by_time)[-1],
  MeanCV = colMeans(cv_by_time[, -1], na.rm = TRUE)
)

# location whose CV is closest to the median
loc_acf <- cv_location_summary$Location[
  which.min(abs(cv_location_summary$MeanCV -
                median(cv_location_summary$MeanCV)))
]

df_loc <- data_transposed[[loc_acf]]

# median profile across the year
typical_day <- apply(df_loc, 2, median)

# ACF (lags up to 4 hours)
acf_obj <- acf(typical_day, lag.max = 48, plot = FALSE)

acf_df <- data.frame(
  Lag = acf_obj$lag * 5,
  ACF = as.numeric(acf_obj$acf)
)
acf <- ggplot(acf_df, aes(x = Lag, y = ACF)) +
  geom_segment(aes(xend = Lag, yend = 0), color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = paste("Temporal Autocorrelation (ACF):", loc_acf),
    x = "Lag (minutes)",
    y = "Autocorrelation"
  ) +
  theme_minimal() +  theme(plot.title = element_text(size = 7))

cv | acf
```

```{r spatial-corr, fig.height= 3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Spatial Correlation: Daily Total Traffic Across 26 Locations", fig.pos='h'}
library(corrplot)

# 1. Compute daily total traffic for each location
daily_totals <- data.frame(matrix(nrow = 384, ncol = 0))

for (loc in names(data_list)) {
  X <- data_list[[loc]]  # 288 timepoints × 384 days
  totals <- colSums(X)   # total traffic per day
  daily_totals[[loc]] <- totals
}

# 2. Correlation matrix across 26 locations
location_cor <- cor(daily_totals)

# 3. Correlogram
corrplot(
  location_cor,
  method = "color",
  type = "upper",
  tl.col = "black",
  tl.cex = 0.6,
  col = colorRampPalette(c("#ff4d00", "#B6D6A8", "#2166AC"))(200),
  mar = c(0, 0, 2, 0)
)

```

## Methodology
The traffic dataset is high-dimensional, functional in nature (with $p=288$ time points per day), and exhibits substantial temporal dependence.

Consequently, dimension reduction constitutes a fundamental component of the anomaly detection framework with PCA serving as the primary dimension-reduction mechanism, as each daily traffic profile is represented by a matrix $X \in \mathbb{R}^{n \times p}$, and PCA assumes that although each curve $x_i$ lies in a high-dimensional ambient space $\mathbb{R}^p$, its intrinsic variation is concentrated on a low-dimensional manifold. This representation is consistent with standard functional data analysis practice, where curves are expressed in a reduced basis and where PCA provides a computationally efficient empirical basis for large-scale datasets.

For each location, the $384 \times 288$ traffic matrix $X$ was transposed so that rows corresponded to days and columns to time points. PCA was then conducted on the centered traffic matrix, $X_c = X - \mathbf{1}_n \bar{x}^{\mathsf{T}}$, where \(\bar{x}\) denotes the sample mean profile. Let $V = [v_1, \ldots, v_p]$ denote the orthonormal loading functions (the empirical eigenbasis), and let $S = X_c V$ denote the corresponding score matrix. The score of day $i$ on component $j$ is given by $s_{ij} = X_{c,i}^{\mathsf{T}} v_j$. The number of retained components \(k\) was selected via the 90\% variance-explained criterion: $\frac{\sum_{j = 1}^{k} \lambda_j}{\sum_{j = 1}^{p} \lambda_j} \ge 0.90$, where $\lambda_j = \sigma_j^2$ denotes the variance explained by component $j$, which can be obtained through the squared singular values of the sample covariance matrix. This process highlights major regimes, like a morning peak, and discards higher-frequency noise.

Then anomalies were identified directly from the PCA score matrix $S \in \mathbb{R}^{n \times k}$ as PCA scores are uncorrelated and form an orthogonal basis. For each component $j$, a day $i$ was flagged as anomalous if $s_{ij} < Q_{1,j} - 1.5\,\mathrm{IQR}_j$ or $s_{ij} > Q_{3,j} + 1.5\,\mathrm{IQR}_j$, where $Q_{1,j}$, $Q_{3,j}$, and $\mathrm{IQR}_j$ denotes the first quartile, third quartile, and interquartile range of component $j$ respectively. In comparison to Mahalanobis-distance methods, this boxplot method is robust enough to not assume normality and is standard in functional data outlier detection, which is important as PC scores are not guaranteed to be multivariate normally distributed (MVN). Boxplots give interpretable, location-specific anomaly sets that can be classified by time-of-day [@shang2010exploratory].

FA provides an alternative dimension-reduction framework. FA postulates that an observed random vector $x$ satisfies $x = \Lambda z + \varepsilon$, where $z$ is a lower-dimensional latent vector, $\Lambda$ is a loading matrix (factor scores and loadings), and $\varepsilon$ represents idiosyncratic noise. FA requires a full-rank, invertible sample covariance matrix; estimation therefore proceeds via iterated PCA and not on the raw data, until uniqueness variances converge.

FA anomalies were also detected using the same $1.5 \times IQR$ rule applied to the factor score matrix $F$, where $f_{ij} < Q_{1,j} - 1.5\,\mathrm{IQR}_j$ or $f_{ij} > Q_{3,j} + 1.5\,\mathrm{IQR}_j$. Because FA captures deviations from latent structural factors rather than maximizing total variance, FA anomalies correspond to days whose patterns violate the inferred latent structure like shifted peaks, whereas PCA anomalies reflect variance-aligned distortions like spikes associated with incidents.

ICA was applied to the PCA scores to extract statistically independent latent signals embedded within the traffic profiles. ICA assumes whitened inputs with identity covariance and therefore requires PCA preprocessing, like in FA [@hyvarinen2000ica]. ICA yields the decomposition $S_{\text{PCA}} = A S_{\text{ICA}}$, where $S_{\text{ICA}}$ contains the source signals (scores) and $A$ is the mixing matrix (loadings).

ICA anomalies were detected via the same $1.5 \times \mathrm{IQR}$ rule applied to the independent source scores. Intuitively, ICA anomalies represent rare independent micro-events that sharply distort the traffic curve of a different location, for example a sudden dip/spike that only lasts a few intervals that PCA smooths out, or odd jumps that FA distributes across factors and randomness. 

All anomalies identified across PCA, FA, and ICA were projected onto their two-dimensional principal component subspace and partitioned using k-means clustering [@piech2013kmeans]. This method was selected for its computational efficiency and suitability for continuous Euclidean feature spaces. The number of clusters was chosen by maximizing the average silhouette coefficient: $k^\ast = \arg\max_k \left\{\frac{1}{N} \sum_{i=1}^{N} \frac{b(i) - a(i)}{\max\{a(i), b(i)\}} \right\}$, where $a(i)$ is the average within-cluster distance and $b(i)$ is the minimum average between-cluster distance [@rousseeuw1987silhouettes]. This procedure yields interpretable groups of anomalies that reflect distinct structural perturbations in daily traffic dynamics. Taken together, PCA, FA, and ICA form a benchmark set: PCA captures global variance-driven deviations, FA captures structural inconsistencies relative to latent factors, and ICA captures independent localized perturbations. Using all three offers a comprehensive view of anomalous behavior from orthogonal interpretive perspectives: variance, latent structure, and independence. This ensures that anomalies detected are robust to modeling assumptions and interpretable in terms of their functional, temporal, and structural characteristics.

## Results
```{r results-setup, echo=FALSE, message=FALSE, warning=FALSE}


file <- "traffic.xlsx"
sheet_names <- getSheetNames(file)
num_sheets <- length(sheet_names)

df <- lapply(sheet_names, function(sheet) {
  as.matrix(read.xlsx(file, sheet = sheet, colNames = TRUE))
})
names(df) <- sheet_names
```
```{r helpers, echo=FALSE, message=FALSE, warning=FALSE}
choose_k_pca <- function(pca, threshold = 0.90) {
  var_expl <- pca$sdev^2 / sum(pca$sdev^2)
  cumvar <- cumsum(var_expl)
  k <- which(cumvar >= threshold)[1]
  return(k)
}

find_anomalies_from_scores <- function(score_mat, multiplier = 1.5) {
  n_days <- nrow(score_mat)
  is_outlier <- rep(FALSE, n_days)
  
  for (j in seq_len(ncol(score_mat))) {
    x <- score_mat[, j]
    stats <- boxplot.stats(x, coef = multiplier)
    is_outlier[which(x %in% stats$out)] <- TRUE
  }
  
  which(is_outlier)
}
```

```{r analysis, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
analyze_location <- function(loc_name,
                             X,
                             var_expl_threshold = 0.90,
                             max_factors = 3,
                             anomaly_coef = 1.5,
                             do_ica = TRUE,
                             n_ica_comp = 3) {
  
  message("Processing: ", loc_name)
  
  # tranpose
  X_t <- t(X)  # rows = days, cols = timepoints
  X_centered <- scale(X_t, center = TRUE, scale = FALSE)

  #pca

  pca <- prcomp(X_centered, center = FALSE, scale. = FALSE)
  k_pca <- choose_k_pca(pca, threshold = var_expl_threshold)
  
  pca_scores <- pca$x[, 1:k_pca, drop = FALSE]
  pca_loadings <- pca$rotation[, 1:k_pca, drop = FALSE]
  pca_anom_idx <- find_anomalies_from_scores(pca_scores, multiplier = anomaly_coef)
  pca_anom_days <- rownames(pca_scores)[pca_anom_idx]
  
  # FA on pca scores
  fa_model <- NULL
  fa_scores <- NULL
  fa_loadings <- NULL
  fa_anom_days <- character(0)
  
  n_factors <- min(max_factors, k_pca, 5)
  n_pcs_for_fa <- min(50, k_pca)
  n_factors_fa <- min(n_factors, n_pcs_for_fa - 1)
  # due to rank issues
  if (n_factors_fa >= 1 && n_pcs_for_fa >= 3) {
    fa_model <- tryCatch(
      factanal(pca_scores[, 1:n_pcs_for_fa, drop = FALSE], 
               factors = n_factors_fa, 
               scores = "regression", 
               rotation = "varimax"),
      error = function(e) NULL
    )
    # due to rank issues
    if (!is.null(fa_model)) {
      fa_scores <- fa_model$scores
      fa_loadings <- pca_loadings[, 1:n_pcs_for_fa] %*% fa_model$loadings[, , drop = FALSE]
      fa_anom_idx <- find_anomalies_from_scores(fa_scores, multiplier = anomaly_coef)
      fa_anom_days <- rownames(fa_scores)[fa_anom_idx]
    }
  }
  
  # ICA
  ica_result <- NULL
  ica_scores <- NULL
  ica_loadings <- NULL
  ica_anom_days <- character(0)
  
  if (do_ica && k_pca >= 2) {
    n_ica_to_use <- min(n_ica_comp, k_pca)
    
    ica_result <- tryCatch(
      fastICA(pca_scores, n.comp = n_ica_to_use, method = "C"),
      error = function(e) NULL
    )
  #worried about matrix
    if (!is.null(ica_result)) {
      ica_scores <- ica_result$S
      if (is.null(rownames(ica_scores))) {
        rownames(ica_scores) <- rownames(pca_scores)
      }
      
      ica_loadings <- pca_loadings[, 1:n_ica_to_use, drop = FALSE] %*% ica_result$A
      ica_anom_idx <- find_anomalies_from_scores(ica_scores, multiplier = anomaly_coef)
      ica_anom_days <- rownames(ica_scores)[ica_anom_idx]
    }
  }
  
  #results
  list(
    location = loc_name,
    pca = pca,
    k_pca = k_pca,
    pca_scores = pca_scores,
    pca_loadings = pca_loadings,
    pca_anom_days = pca_anom_days,
    fa_model = fa_model,
    fa_scores = fa_scores,
    fa_loadings = fa_loadings,
    fa_anom_days = fa_anom_days,
    ica = ica_result,
    ica_scores = ica_scores,
    ica_loadings = ica_loadings,
    ica_anom_days = ica_anom_days
  )
}

# eliminate
location_results <- lapply(names(df), function(loc_name) {
  analyze_location(
    loc_name = loc_name,
    X = df[[loc_name]],
    var_expl_threshold = 0.90,
    max_factors = 3,
    anomaly_coef = 1.5,
    do_ica = TRUE
  )
})
names(location_results) <- names(df)
```

```{r view-anomalies, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
for (loc_name in names(location_results)) {
  res <- location_results[[loc_name]]
  cat("\n", rep("=", 60), "\n", sep = "")
  cat("Location:", loc_name, "\n")
  cat(rep("=", 60), "\n")
  cat("PCA components:", res$k_pca, "\n")
  cat("PCA anomalies (", length(res$pca_anom_days), "):", 
      paste(res$pca_anom_days, collapse = ", "), "\n")
  cat("FA anomalies (", length(res$fa_anom_days), "):", 
      paste(res$fa_anom_days, collapse = ", "), "\n")
  cat("ICA anomalies (", length(res$ica_anom_days), "):", 
      paste(res$ica_anom_days, collapse = ", "), "\n")
}
```

PCA retained between 2 and 9 components across all 26 locations, consistently explaining at least 90% of total variance, with cumulative explained variance ranging from 0.9006 to 0.9404.

```{r plot-pca-loading, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="PCA Loadings for 2 Locations with Anomalies", fig.pos='H'}

# Specify the two locations explicitly for paper
plot_locs <- c("Loc7", "Loc17")

plot_pca_loadings <- function(res, loc_name, n_comp = 3) {
  loadings <- res$pca_loadings[, 1:min(n_comp, ncol(res$pca_loadings)), drop = FALSE]
  time_hours <- seq(0, 24, length.out = nrow(loadings))
  
  df <- data.frame(Time = time_hours, loadings)
  colnames(df) <- c("Time", paste0("PC", 1:ncol(loadings)))
  
  df_long <- tidyr::pivot_longer(df, cols = -Time,
                                 names_to = "Component",
                                 values_to = "Loading")
  
  ggplot(df_long, aes(x = Time, y = Loading, color = Component)) +
    geom_line(size = 0.9) +
    facet_wrap(~Component, ncol = 1, scales = "free_y") +
    labs(title = paste("PCA Loadings:", loc_name),
         x = "Hour of Day",
         y = "Loading") +
    theme_minimal(base_size = 8) +
    scale_x_continuous(breaks = seq(0, 24, 4))
}

# Produce two PCA plots
pca_plot1 <- plot_pca_loadings(location_results[[plot_locs[1]]], plot_locs[1])
pca_plot2 <- plot_pca_loadings(location_results[[plot_locs[2]]], plot_locs[2])

# patchwork side by side
pca_plot1 | pca_plot2

```

PCA detected between 4 and 31 anomalous days per location, with most locations falling in the 15–25 anomaly range. This demonstrates that although each daily curve contains 288 five-minute observations, the dominant variation is always low-dimensional.

Across locations, the first two principal components (PCs) followed consistent functional interpretations:

1. PC1 (global amplitude):
Loadings were strictly non-negative and broadly elevated across the 24-hour period, indicating that PC1 captures overall daily traffic volume, such as comparing high-traffic days against quiet days.

2. PC2 (shape distortion or timing shift):
PC2 loadings exhibited a morning–evening contrast, with positive loadings during morning peaks and negative loadings in the evening (or vice versa).
This component reflects differences in peak timing, where anomalously shifted or flattened peaks appear as extreme PC2 score values.

3. Higher order PCs (3-9):
They would continue to capture localized deviations. 

Intuitively, these anomalies correspond to days with unusually large or small PC scores relative to the interquartile range for at least one retained component. Because PCA aligns with variance-maximizing directions, these anomalies could represent large-scale distortions such as full-day surges, holiday traffic patterns, or major disruptions.

```{r pca-summary, fig.width = 3, fig.height=5, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
pca_summary <- data.frame(
  Location = names(location_results),
  k_pca = sapply(location_results, function(res) res$k_pca),
  Variance_Explained = sapply(location_results, function(res) {
    pca <- res$pca
    var_expl <- pca$sdev^2 / sum(pca$sdev^2)
    cumvar <- cumsum(var_expl)
    round(cumvar[res$k_pca], 4)
  }),
  PCA_Anomaly_Count = sapply(location_results, function(res) length(res$pca_anom_days))
)
rownames(pca_summary) <- NULL
print(pca_summary)
```
```{r pca-boxplots-specific, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Boxplot for 1 PCA Location with Anomalies", fig.pos='H'}
plot_pca_boxplot <- function(res, loc_name) {
  if (is.null(res$pca_scores)) return(NULL)
  # fidn the anomalies 
  scores <- res$pca_scores
  days <- rownames(scores)
  if (is.null(days)) return(NULL)

  pca_anom <- res$pca_anom_days

  df_long <- data.frame(
    Day = rep(days, ncol(scores)),
    PC = rep(colnames(scores), each = nrow(scores)),
    Score = as.vector(scores),
    stringsAsFactors = FALSE
  )

  df_long$AnomalyType <- ifelse(df_long$Day %in% pca_anom, "PCA Anomaly", "Normal")
  # graph
  ggplot(df_long, aes(x = PC, y = Score)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(data = subset(df_long, AnomalyType == "Normal"),
                color = "gray70", alpha = 0.3, width = 0.1, size = 0.8) +
    geom_point(data = subset(df_long, AnomalyType == "PCA Anomaly"),
               aes(color = "PCA Anomaly"), size = 1.2) +
    scale_color_manual(values = c("PCA Anomaly" = "red")) +
    labs(title = paste("PCA Boxplots -", loc_name),
         subtitle = paste("Anomalies:", length(pca_anom))) +
    theme_minimal(base_size = 8) +
    theme(legend.position = "bottom")
}
# graph specifically for this location for paper
pca_locs <- c("Loc7")

pca_plots <- lapply(pca_locs, function(loc) {
  plot_pca_boxplot(location_results[[loc]], loc)
})

wrap_plots(pca_plots, ncol = 1)
```

Factor Analysis successfully converged for 17 of 26 locations, always extracting 3 factors. FA identified between 5-16 anomalous days at successful locations. From the output messages, convergence failures usually occured when PCA dimensionality was too low (2-3). 

```{r fa-loadings, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="FA Loadings for 2 Locations with Anomalies"}

# Specify locations explicitly
fa_locs <- c("Loc6", "Loc23")

plot_fa_loadings <- function(res, loc_name) {
  if (is.null(res$fa_loadings)) {
    message("FA loadings unavailable for ", loc_name)
    return(NULL)
  }
  
  loadings <- res$fa_loadings
  n_factors <- ncol(loadings)

  time_hours <- seq(0, 24, length.out = nrow(loadings))
  df <- data.frame(Time = time_hours, loadings)
  colnames(df) <- c("Time", paste0("Factor", 1:n_factors))

  df_long <- tidyr::pivot_longer(df, cols = -Time,
                                 names_to = "Factor",
                                 values_to = "Loading")

  ggplot(df_long, aes(x = Time, y = Loading, color = Factor)) +
    geom_line(size = 0.9) +
    facet_wrap(~Factor, ncol = 1, scales = "free_y") +
    labs(title = paste("FA Loadings:", loc_name),
         x = "Hour", y = "Loading") +
    theme_minimal(base_size = 8)
}

fa_plot1 <- plot_fa_loadings(location_results[[fa_locs[1]]], fa_locs[1])
fa_plot2 <- plot_fa_loadings(location_results[[fa_locs[2]]], fa_locs[2])

fa_plot1 | fa_plot2
```

Across locations, the first FA loadings followed these interpretations:

1. FA1 (baseline daily volume)

2. FA2, FA3 (shape distortions):
They are not variance-maximizing directions. 

Intuitively, these anomalies represent days that deviate from the latent factor structure, rather than simply from variance. While PCA anomalies capture overall surges or large-scale changes, FA anomalies identify violations of latent behavioral patterns. That could be peak shifting within latent factors, inconsistent “shape modes” of daily traffic, or breakdowns of the usual relationships between morning and afternoon traffic. Because of the reduced anomaly identification, FA is more conservative and structurally selective.

```{r fa-summary, fig.width = 3, fig.height=5, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
fa_summary <- data.frame(
  Location = names(location_results),
  FA_Success = sapply(location_results, \(res) !is.null(res$fa_model)),
  Factors_Extracted = sapply(location_results, function(res) {
    if (is.null(res$fa_model)) return(0)
    ncol(res$fa_model$loadings)
  }),
  FA_Anomaly_Count = sapply(location_results, function(res) length(res$fa_anom_days))
)
rownames(fa_summary) <- NULL
print(fa_summary)
```
```{r fa-boxplots-specific, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Boxplot for 1 FA Location with Anomalies", fig.pos='H'}
plot_fa_boxplot <- function(res, loc_name) {
  if (is.null(res$fa_scores)) return(NULL)

  scores <- res$fa_scores
  days <- rownames(scores)
  if (is.null(days)) return(NULL)

  fa_anom <- res$fa_anom_days

  df_long <- data.frame(
    Day = rep(days, ncol(scores)),
    Factor = rep(paste0("Factor", seq_len(ncol(scores))), each = nrow(scores)),
    Score = as.vector(scores),
    stringsAsFactors = FALSE
  )

  df_long$AnomalyType <- ifelse(df_long$Day %in% fa_anom, "FA Anomaly", "Normal")

  ggplot(df_long, aes(x = Factor, y = Score)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(data = subset(df_long, AnomalyType == "Normal"),
                color = "gray70", alpha = 0.3, width = 0.1, size = 0.8) +
    geom_point(data = subset(df_long, AnomalyType == "FA Anomaly"),
               aes(color = "FA Anomaly"), size = 1.2) +
    scale_color_manual(values = c("FA Anomaly" = "blue")) +
    labs(title = paste("FA Boxplots -", loc_name),
         subtitle = paste("Anomalies:", length(fa_anom))) +
    theme_minimal(base_size = 8) +
    theme(legend.position = "bottom")
}

fa_locs <- c("Loc6")

fa_plots <- lapply(fa_locs, function(loc) {
  plot_fa_boxplot(location_results[[loc]], loc)
})

wrap_plots(fa_plots, ncol = 1)
```

FA score distributions appear more compact, with fewer extreme outliers. FA captures deviations in latent covariance structure (e.g., changes in the relationship between morning and evening peaks) rather than raw amplitude. The narrow score boxes suggest stable relationships between their latent factors across days. When FA does produce outliers, they appear as isolated points, indicating rare disruptions in factor relationships. This narrower spread explains why FA produces moderate anomaly counts—it flags structural departures, not amplitude-driven ones.

ICA converged successfully at all 26 locations, producing 2–3 independent components depending on PCA dimensionality as expected after PCA whitening. ICA detected between 3 and 22 anomalies, typically between 8 and 15 anomalies per location.

```{r ica-loadings-specific, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="ICA Loadings for 2 Locations with Anomalies"}

# Specify the two locations you want
ica_locs <- c("Loc24", "Loc25")

plot_ica_loadings_specific <- function(res, loc_name, max_plot_comp = 4) {
  if (is.null(res$ica) || is.null(res$ica$A) || ncol(res$ica$A) == 0) {
    message("ICA loadings unavailable for ", loc_name)
    return(NULL)
  }
  
  # Extract A matrix (mixing matrix)
  loadings <- res$ica$A
  n_comp <- ncol(loadings)
  n_comp_to_plot <- min(n_comp, max_plot_comp)
  loadings <- loadings[, 1:n_comp_to_plot, drop = FALSE]
  
  # Time axis (matching the FA example)
  time_hours <- seq(0, 24, length.out = nrow(loadings))
  df <- data.frame(Time = time_hours, loadings)
  colnames(df) <- c("Time", paste0("Source", 1:n_comp_to_plot))
  
  df_long <- tidyr::pivot_longer(df, cols = -Time,
                                 names_to = "Source",
                                 values_to = "Loading")
  
  ggplot(df_long, aes(x = Time, y = Loading, color = Source)) +
    geom_line(size = 0.9) +
    facet_wrap(~Source, ncol = 1, scales = "free_y") +
    labs(title = paste("ICA Loadings:", loc_name),
         x = "Hour", y = "Loading/Mixing Weight") +
    theme_minimal(base_size = 8)
}

# Generate the two ICA plots
ica_plot1 <- plot_ica_loadings_specific(location_results[[ica_locs[1]]], ica_locs[1])
ica_plot2 <- plot_ica_loadings_specific(location_results[[ica_locs[2]]], ica_locs[2])

# Display side by side using patchwork
ica_plot1 | ica_plot2
```

Across all locations, the first sources followed these functional interpretations:

1. ICA Source 1 (localized spikes):
The shape is a sharp positive or negative jump over a very short interval (10–30 minutes). This could mean a sudden incident, brief surge, or lane closure, or short-lived dip (sometimes negative spike). It is statistically independent from the smooth daily curve. 

2. ICA Source 2 (independent morning distruption):
The is a strong swing isolated around around 7–10 AM. This could be interpreted as morning congestion anomalies school-day vs. holiday pattern, morning-only incident, or weather-related delays. These don’t necessarily correlate with evening patterns as they are independent from other components.

3. ICA Source 3 (independent evening disruption):
A bump/dip concentrated around 4–7 PM can be interpreted as evening rush anomalies, evening event traffic, or some end-of-day incident. ICA finds this separate from morning events because morning/evening anomalies often do not co-occur.

Intuitively, ICA highlights micro-structure anomalies that PCA smooths out and FA diffuses across latent factors. ICA anomalies often overlapped with PCA and FA anomalies, but identified unique, fine-grained disturbances, consistent with ICA’s sensitivity to localized, high-frequency deviations. These could be: abrupt, short-lived spikes, dips at specific time intervals, independent transient disruptions (perhaps weather or accidents). In observation, university traffic is regular but shaped by overlapping processes, ICA is uniquely suited to separate them into interpretable underlying signals. Concretely, ICA would reveal class changeover cycles (large groups exiting lecture halls on the hour, groups commuting to specific locations), residence-to-campus migration patterns in the morning, library closing times, sports events. Then, anomalies could be irregular pedestrian surges on certain days like the sports events, road closures, and students going to exams. These signals exist simultaneously and overlap; PCA cannot fully separate them because PCA components remain orthogonal but not independent. ICA isolates each hidden source.

```{r ica-summary, fig.width = 3, fig.height=5, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
ica_summary <- data.frame(
  Location = names(location_results),
  ICA_Success = sapply(location_results, \(res) !is.null(res$ica_scores)),
  ICA_Components = sapply(location_results, function(res) {
    if (is.null(res$ica_scores)) return(0)
    ncol(res$ica_scores)
  }),
  ICA_Anomaly_Count = sapply(location_results, function(res) length(res$ica_anom_days))
)
rownames(ica_summary) <- NULL
print(ica_summary)
```
```{r ica-boxplots, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Boxplot for 1 ICA Location with Anomalies",  fig.pos='H'}
# ica get the anomalies
plot_ica_score_boxplot <- function(res, loc_name) {

  if (is.null(res$ica_scores)) return(NULL)
  
  scores <- res$ica_scores
  days <- rownames(scores)
  if (is.null(days)) return(NULL)
  
  ica_anom <- res$ica_anom_days
  
  df_long <- data.frame(
    Day = rep(days, ncol(scores)),
    Source = rep(paste0("Source", seq_len(ncol(scores))), each = nrow(scores)),
    Score = as.vector(scores),
    stringsAsFactors = FALSE
  )
  
  df_long$AnomalyType <- ifelse(df_long$Day %in% ica_anom, "ICA Anomaly", "Normal")
  
  ggplot(df_long, aes(x = Source, y = Score)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(data = subset(df_long, AnomalyType == "Normal"),
                color = "gray70", alpha = 0.3, width = 0.15, size = 1) +
    geom_point(data = subset(df_long, AnomalyType == "ICA Anomaly"),
               aes(color = "ICA Anomaly"), size = 1.2) +
    scale_color_manual(values = c("ICA Anomaly" = "purple")) +
    labs(title = paste("ICA Source Score Boxplots -", loc_name),
         subtitle = paste("Anomalies detected:", length(ica_anom)),
         x = "Independent Component",
         y = "ICA Score") +
    theme_minimal(base_size = 9) +
    theme(legend.position = "bottom")
}

# graph for specific lcoatio
ica_locs <- c("Loc24")

ica_plots <- lapply(ica_locs, function(loc) {
  plot_ica_score_boxplot(location_results[[loc]], loc)
})

# ---- Combine with patchwork ----
wrap_plots(ica_plots, ncol = 1)
```

By definition, ICA components often have non-Gaussian, heavy-tailed distributions, so the boxplots for ICA components typically show skewness and occasional extremely high or low points like in these last 2 sources. These ICA-specific outliers correspond to short, localized perturbations rather than systematic shifts, explaining why ICA’s anomaly detections differ the most from PCA and FA.

```{r summary-all-locations, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Create summary table 
summary_df <- data.frame(
  Location = names(location_results),
  
  # Total unique anomalies across all methods
  Total_Anomalies = sapply(location_results, \(x) 
    length(union(union(x$pca_anom_days, x$fa_anom_days), x$ica_anom_days))),
  
  # All three methods detected
  All_Three = sapply(location_results, \(x) 
    length(intersect(intersect(x$pca_anom_days, x$fa_anom_days), x$ica_anom_days))),
  
  # Two methods detected this is basically set diff, intersect, union
  PCA_FA = sapply(location_results, \(x)
    length(setdiff(intersect(x$pca_anom_days, x$fa_anom_days), x$ica_anom_days))),
  
  PCA_ICA = sapply(location_results, \(x)
    length(setdiff(intersect(x$pca_anom_days, x$ica_anom_days), x$fa_anom_days))),
  
  FA_ICA = sapply(location_results, \(x)
    length(setdiff(intersect(x$fa_anom_days, x$ica_anom_days), x$pca_anom_days))),
  
  # Single method only
  PCA_Only = sapply(location_results, \(x)
    length(setdiff(setdiff(x$pca_anom_days, x$fa_anom_days), x$ica_anom_days))),
  
  FA_Only = sapply(location_results, \(x)
    length(setdiff(setdiff(x$fa_anom_days, x$pca_anom_days), x$ica_anom_days))),
  
  ICA_Only = sapply(location_results, \(x)
    length(setdiff(setdiff(x$ica_anom_days, x$pca_anom_days), x$fa_anom_days))),
  
  FA_Success = sapply(location_results, \(x) !is.null(x$fa_model)),
  ICA_Success = sapply(location_results, \(x) !is.null(x$ica_scores))
)

df_long_summary <- summary_df %>%
  pivot_longer(cols = -Location,
               names_to = "AnomalyType",
               values_to = "Count") %>%
  filter(Count > 0)



print(summary_df)
```

```{r barchart, fig.height = 4, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Proportion of Total Anomaly Counts", fig.pos='H'}
df_long_summary <- summary_df %>%
  pivot_longer(cols = c(PCA_Only, FA_Only, ICA_Only,
                        PCA_FA, PCA_ICA, FA_ICA, All_Three),
               names_to = "AnomalyType",
               values_to = "Count") %>%
  filter(Count > 0)

fill_colors <- c(
  "PCA_Only" = "red",
  "FA_Only" = "blue",
  "ICA_Only" = "green",
  "PCA_FA" = "purple",
  "PCA_ICA" = "#FF7F50",
  "FA_ICA" = "#00CED1",
  "All_Three" = "black"
)

ggplot(df_long_summary, aes(x = Location, y = Count, fill = AnomalyType)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = fill_colors,
                    labels = c(
                      "PCA_Only" = "PCA Only",
                      "FA_Only" = "FA Only",
                      "ICA_Only" = "ICA Only",
                      "PCA_FA" = "PCA & FA",
                      "PCA_ICA" = "PCA & ICA",
                      "FA_ICA" = "FA & ICA",
                      "All_Three" = "All 3 Methods"
                    )) +
  labs(title = "Breakdown of Anomaly Types by Location",
       x = "Location",
       y = "Number of Anomalous Days",
       fill = "Anomaly Source") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The breakdown of anomaly types across all 26 locations reveals a striking pattern: although PCA, FA, and ICA are applied to the same daily traffic curves, the vast majority of anomalies are not jointly detected by all three methods. PCA accounts for the largest portion of anomalies overall, while FA and ICA detect fewer and more selective subsets. This result is fully consistent with the methodological roles of each decomposition. PCA identifies anomalies that manifest as large-scale deviations along the axes of highest variance—for example, abnormally high daily volume, suppressed flow, or significant timing distortions in morning or evening peaks. Because daily traffic curves contain substantial natural variability, PCA’s variance-maximizing nature makes it highly sensitive to any global shift that pulls a day outside the main data manifold, producing relatively high anomaly counts.

In the context of the project’s central goal—identifying and characterizing atypical traffic days at each location—this asymmetry between methods is not a weakness but a strength. The differences in anomaly detection highlight that PCA, FA, and ICA provide complementary anomaly signatures. PCA acts as a broad, variance-aligned detector of major disruptions; FA isolates shape-based irregularities that contradict dominant commuting regimes; and ICA uncovers independent micro-events that reveal fine-grained operational issues. Together, the lack of complete overlap validates the design of the analysis: anomalies in traffic are multi-layered, and understanding them requires a decomposition-based multivariate lens rather than reliance on any single method. If the locations were labeled, there would be further opportunity to reverse engineer anomaly causes based on the contexts of university life and the goals of each multivariate method. 

The temporal anomaly sequence plots below reveal that anomalies are not uniformly distributed across the 384-day period; instead, they occur in method-specific bursts that reflect distinct types of underlying disruptions. Locations 7 and 23 exhibit concentrated clusters of anomalies around specific day ranges, suggesting periods of sustained irregularity in traffic flow that could correspond to broader system-level disruptions (like construction phases, seasonal events, road closure due to parade). In contrast, other locations show sporadic anomalies, indicating that disruptions at these sites are more idiosyncratic and likely reflect local micro-events rather than persistent structural changes. Since the dataset is supposed to mimic the traffic congestion at the University of Toronto, something could be said about large groups of students leaving lectures every hour and automatic walk signs. This reinforces the need for a multi-method detection framework, as relying on any single method would obscure the nuanced ways in which traffic deviates over the year.

```{r plot-anomalies-vs-normal, fig.height = 6, fig.width=13, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Timeline of Select Anomalies", fig.pos='H'}
anomaly_timeline <- function(res, loc_name) {
  all_days <- rownames(res$pca_scores)
  df_timeline <- data.frame(DayName = all_days, DayIndex = 1:length(all_days))
  
  df_timeline <- df_timeline %>%
    mutate(AnomalyType = case_when(
      DayName %in% intersect(intersect(res$pca_anom_days, res$fa_anom_days), res$ica_anom_days) ~ "All Three",
      DayName %in% setdiff(intersect(res$pca_anom_days, res$fa_anom_days), res$ica_anom_days) ~ "PCA & FA",
      DayName %in% setdiff(intersect(res$pca_anom_days, res$ica_anom_days), res$fa_anom_days) ~ "PCA & ICA",
      DayName %in% setdiff(intersect(res$fa_anom_days, res$ica_anom_days), res$pca_anom_days) ~ "FA & ICA",
      DayName %in% setdiff(setdiff(res$pca_anom_days, res$fa_anom_days), res$ica_anom_days) ~ "PCA Only",
      DayName %in% setdiff(setdiff(res$fa_anom_days, res$pca_anom_days), res$ica_anom_days) ~ "FA Only",
      DayName %in% setdiff(setdiff(res$ica_anom_days, res$pca_anom_days), res$fa_anom_days) ~ "ICA Only",
      TRUE ~ "Normal"
    ))

  df_anomalies <- df_timeline %>% filter(AnomalyType != "Normal")

  if (nrow(df_anomalies) == 0) {
    message("No anomalies to plot for ", loc_name)
    return(NULL)
  }

  ggplot(df_anomalies, aes(x = DayIndex, y = 1)) +
    
    # Clean horizontal baseline
    geom_hline(yintercept = 1, color = "gray85", linewidth = 0.3) +
    
    # nomaly points only
    geom_point(aes(color = AnomalyType, shape = AnomalyType), size = 3) +

    scale_color_manual(values = c(
      "PCA Only" = "red",
      "FA Only" = "blue",
      "ICA Only" = "green",
      "PCA & FA" = "purple",
      "PCA & ICA" = "#FF7F50",
      "FA & ICA" = "#00CED1",
      "All Three" = "black"
    )) +
    scale_shape_manual(values = c(
      "PCA Only" = 19,
      "FA Only" = 17,
      "ICA Only" = 15,
      "PCA & FA" = 8,
      "PCA & ICA" = 10,
      "FA & ICA" = 13,
      "All Three" = 4
    )) +
    labs(title = paste("Anomaly Temporal Sequence -", loc_name),
         x = "Day Index (Time Sequence)",
         y = "",
         color = "Detection Source",
         shape = "Detection Source") +
    theme_minimal() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.position = "bottom")
}

# ---- Locations you want ----
target_locs <- c("Loc7", "Loc17", "Loc6", "Loc23", "Loc24", "Loc25")

# ---- Wrapper for robust plotting ----
plot_anomaly_timeline <- function(loc) {
  res <- location_results[[loc]]
  if (is.null(res)) return(NULL)
  anomaly_timeline(res, loc)
}

# ---- Generate the plots ----
timeline_plots_raw <- lapply(target_locs, plot_anomaly_timeline)

# Filter out NULLs if some locations have no anomalies
timeline_plots <- Filter(function(x) inherits(x, "ggplot"), timeline_plots_raw)

wrap_plots(timeline_plots, ncol = 2)
```

The PCA-space visualization of clustered anomalies reveals several meaningful and distinct groups, even though the clustering was performed across all locations and based on only the common first 2 PCs. The silhouette analysis selected K = 5, indicating that anomalies naturally separate into five coherent behavioral modes rather than forming a cloud. The olive cluster is dense and tightly packed at the center, going by PC1 and PC2 definitions, could mean that these anomalies may be caused by light fluctuations in overall traffic volume rather than structural changes in the daily curve. The remaining clusters were spatially distinct, reflecting more extreme pattern deviations such as shifted peak times, abnormal rush-hour intensities, or overall curve distortions. The presence of similar anomaly types across many locations suggests that some unusual days reflect network-level disruptions, while the smaller clusters indicate rarer, high-severity events. The clear separation between clusters demonstrates that PCA scores effectively encode the structural variability of traffic profiles, enabling interpretable anomaly grouping.

```{r cluster-global-anomalies, fig.height = 3, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="K-means Cluster of Anomalies by 2 PCs", fig.pos='H'}
min_k <- min(sapply(location_results, function(res) res$k_pca))

# Step 2: Collect all anomalies
all_anomalies_list <- lapply(location_results, function(res) {
  anom_days <- union(res$pca_anom_days, 
                     union(res$fa_anom_days, res$ica_anom_days))
  
  if (length(anom_days) == 0) return(NULL)
  
  scores <- res$pca_scores[anom_days, 1:min_k, drop = FALSE]
  
  data.frame(
    Day = rownames(scores),
    Location = res$location,
    scores,
    stringsAsFactors = FALSE
  )
})

# Remove NULL entries
all_anomalies_list <- Filter(Negate(is.null), all_anomalies_list)

# Bind into single dataframe
all_anomalies <- do.call(rbind, all_anomalies_list)
rownames(all_anomalies) <- NULL

  
  # Step 3: Prepare scores for clustering
  anomaly_scores <- all_anomalies[, -(1:2), drop = FALSE]
  scaled_scores <- scale(anomaly_scores)
  
  # Step 4: Find optimal K using silhouette
  silhouette_scores <- data.frame(K = integer(), Silhouette = double())
  
  for (k in 2:min(6, nrow(anomaly_scores) - 1)) {
    km <- kmeans(scaled_scores, centers = k, nstart = 25)
    sil <- silhouette(km$cluster, dist(scaled_scores))
    silhouette_scores <- rbind(silhouette_scores,
                               data.frame(K = k, Silhouette = mean(sil[, 3])))
  }
  
  best_k <- silhouette_scores$K[which.max(silhouette_scores$Silhouette)]
  
  # Step 5: Final clustering
  km_anomalies <- kmeans(scaled_scores, centers = best_k, nstart = 25)
  
  all_anomalies$Cluster <- as.factor(km_anomalies$cluster)
  
  # Step 6: Silhouette plot
  sil_plot <- ggplot(silhouette_scores, aes(x = K, y = Silhouette)) +
    geom_line(color = "blue", linewidth = 1) +
    geom_point(size = 3, color = "red") +
    geom_text(aes(label = round(Silhouette, 3)), vjust = -0.5, size = 3) +
    labs(title = "Silhouette Scores Across K",
         x = "Number of Clusters", y = "Average Silhouette Score") +
    theme_minimal()
  
  # Step 7: PCA space cluster plot
  df_plot <- data.frame(
    PC1 = scaled_scores[, 1],
    PC2 = if (ncol(scaled_scores) >= 2) scaled_scores[, 2] else rep(0, nrow(scaled_scores)),
    Cluster = all_anomalies$Cluster,
    Location = all_anomalies$Location
  )
  
  cluster_plot <- ggplot(df_plot, aes(x = PC1, y = PC2, color = Cluster)) +
    geom_point(size = 2.8, alpha = 0.75) +
    theme_minimal() +
    theme(legend.position = "bottom")
  
  # Display side-by-side
cluster_plot
```

## Discussion 
A comparative framework utilizing Principal Component Analysis (PCA), Factor Analysis (FA), and Independent Component Analysis (ICA) to provide a multi-faceted approach to traffic anomaly detection, moving beyond single-method reliance, was successfully employed. The criteria for feature retention (90% variance for PCA/FA) and outlier detection, demonstrated that the three methods provide complementary and largely non-overlapping views of the traffic profile, validating the need for a multi-method benchmark. Findings confirm that while PCA serves as a robust variance-maximizing benchmark, its fundamental limitations as a standalone detector are frequently understated, and FA and ICA are inherently limited and unrobust alone. 

There are several avenues for future research due to limitations. Firstly, all three decomposition methods are fundamentally linear transformations. This assumption may inadequately capture highly non-linear relationships inherent in complex traffic dynamics, such as chaotic system behavior or congestion cascade effects. Non-linear dimensionality reduction techniques, such as Kernel PCA or manifold learning methods, could potentially reveal subtle, non-linear structural patterns missed by the current approach. 

The current reliance on just statistical heuristics (like residual thresholds for PCA/FA and IQR outliers for ICA sources) lacks direct calibration against ground-truth external events (confirmed accidents, more features), limiting the assessment of method sensitivity and specificity. To overcome this, next steps relate to collecting more features of traffic like noting the number of lanes in traffic, speed limits, pedestrian crossings. This would open the gates for a supervised machine learning validation framework and would allow for the rigorous comparison of method performance using tools like Receiver Operating Characteristic (ROC) analysis and enable the optimization of a data-driven threshold.

The final limitation the independent per-location analysis, which is not the detection of system-wide anomalies or coordinated disruptions across multiple sensors. The goal of network-level is to define normalcy, and anomalies relative to the entire system. Then, issues that are invisible or misinterpreted when analyzing individual sensors in isolation can be addressed, as network-level anomaly detection shifts the focus from local fluctuations to the health and behavior of the entire system. Advanced methods like Tensor Decomposition could model the shared temporal and spatial factors simultaneously. By incorporating the network's topological structure, future models can achieve a more precise decoupling of systemic factors from local fluctuations, providing the context, coherence, and causal insight needed for resilient and proactive traffic management across the entire urban network.

## References 
\begin{small}
\textit{The Gemini Flash 2.5 model was used to assist with the formatting of this section.}
\end{small}